"""Shape optimization of a multilayer stack.

The 1D stack consists of alternating materials of index N_LAYER_1 and N_LAYER_2
in the arrangement: N_LAYER_2, N_LAYER_1, N_LAYER_2, N_LAYER_1, ..., N_LAYER_2.

The design parameters are the N layer thicknesses: [t_1, t_2, ..., t_N]. N must
be odd.

Note: N_LAYER_1 must be vacuum because the left and right sides of the stack
are vacuum. This is a limitation of the current setup.
"""

from typing import Callable

from autograd.extend import primitive, defvjp
from autograd import numpy as npa
from autograd import tensor_jacobian_product
import meep as mp
import meep.adjoint as mpa
import nlopt
import numpy as np


RESOLUTION_UM = 800
WAVELENGTH_UM = 1.0
AIR_UM = 1.0
PML_UM = 1.0
NUM_LAYERS = 9
MIN_LAYER_UM = 0.1
MAX_LAYER_UM = 0.5
N_LAYER_1 = 1.0  # TODO (oskooi): support arbitrary materials.
N_LAYER_2 = 1.3
LAYER_PERTURBATION_UM = 1.0 / RESOLUTION_UM
DESIGN_REGION_RESOLUTION_UM = 10 * RESOLUTION_UM
DESIGN_REGION_SIZE = mp.Vector3(0, 0, NUM_LAYERS * MAX_LAYER_UM)
NZ_DESIGN_GRID = int(DESIGN_REGION_SIZE.z * DESIGN_REGION_RESOLUTION_UM) + 1
NZ_SIM_GRID = int(DESIGN_REGION_SIZE.z * RESOLUTION_UM) + 1


def design_region_to_grid(nz: int) -> np.ndarray:
    """Returns the coordinates of the grid for the design region.

    Args:
      nz: number of grid points.

    Returns:
      The 1D coordinates of the grid points.
    """

    z_grid = np.linspace(-0.5 * DESIGN_REGION_SIZE.z, +0.5 * DESIGN_REGION_SIZE.z, nz)

    return z_grid


@primitive
def levelset_and_smoothing(layer_thickness_um: np.ndarray) -> np.ndarray:
    """Returns the density weights for a multilayer stack as a levelset.

    Args:
      layer_thickness_um: thickness of each layer in the stack.

    Returns:
      The density weights as a flattened (1D) array.
    """

    air_padding_um = 0.5 * (DESIGN_REGION_SIZE.z - np.sum(layer_thickness_um))

    weights = np.zeros(NZ_DESIGN_GRID)
    z_design_grid = design_region_to_grid(NZ_DESIGN_GRID)

    # Air padding at left edge
    z_start = 0
    z_end = int(air_padding_um * DESIGN_REGION_RESOLUTION_UM)
    weights[z_start:z_end] = 0

    z_start = z_end
    for j in range(NUM_LAYERS):
        z_end = z_start + int(layer_thickness_um[j] * DESIGN_REGION_RESOLUTION_UM)
        weights[z_start:z_end] = 1 if (j % 2 == 0) else 0
        z_start = z_end

    # Air padding at right edge
    z_end = z_start + int(air_padding_um * DESIGN_REGION_RESOLUTION_UM)
    weights[z_start:z_end] = 0

    # Smooth the design weights by downsampling from the design grid
    # to the simulation grid using bilinear interpolation.
    z_sim_grid = design_region_to_grid(NZ_SIM_GRID)
    smoothed_weights = np.interp(z_sim_grid, z_design_grid, weights)

    return smoothed_weights.flatten()


def levelset_and_smoothing_vjp(
    ans: np.ndarray, layer_thickness_um: np.ndarray
) -> Callable[[np.ndarray], np.ndarray]:
    """Returns a function for computing the vector-Jacobian product."""

    total_layer_thickness_um = np.sum(layer_thickness_um)
    air_padding_um = 0.5 * (DESIGN_REGION_SIZE.z - total_layer_thickness_um)

    jacobian = np.zeros((NZ_SIM_GRID, NUM_LAYERS))

    z_design_grid = design_region_to_grid(NZ_DESIGN_GRID)
    z_sim_grid = design_region_to_grid(NZ_SIM_GRID)

    for i in range(NUM_LAYERS):
        weights = np.zeros(NZ_DESIGN_GRID)

        # Air padding at left edge
        z_start = 0
        z_end = int(air_padding_um * DESIGN_REGION_RESOLUTION_UM)
        weights[z_start:z_end] = 0

        z_start = z_end
        for j in range(NUM_LAYERS):
            layer_um = layer_thickness_um[j]
            if j == i:
                layer_um += LAYER_PERTURBATION_UM
            z_end = z_start + int(layer_um * DESIGN_REGION_RESOLUTION_UM)
            weights[z_start:z_end] = 1 if (j % 2 == 0) else 0
            z_start = z_end

        # Air padding at right edge
        z_end = z_start + int(air_padding_um * DESIGN_REGION_RESOLUTION_UM)
        weights[z_start:z_end] = 0

        # Smooth the design weights by downsampling from the design grid
        # to the simulation grid using bilinear interpolation.
        smoothed_weights = np.interp(z_sim_grid, z_design_grid, weights)

        jacobian[:, i] = (smoothed_weights - ans) / LAYER_PERTURBATION_UM

    return lambda g: np.tensordot(g, jacobian, axes=1)


def input_flux() -> float:
    """Returns the flux generated by the source in vacuum."""

    frequency = 1 / WAVELENGTH_UM
    pml_layers = [mp.PML(direction=mp.Z, thickness=PML_UM)]

    size_z_um = PML_UM + AIR_UM + DESIGN_REGION_SIZE.z + AIR_UM + PML_UM
    cell_size = mp.Vector3(0, 0, size_z_um)

    src_cmpt = mp.Ex
    src_pt = mp.Vector3(0, 0, -0.5 * size_z_um + PML_UM)
    sources = [
        mp.Source(
            mp.GaussianSource(frequency, fwidth=0.1 * frequency),
            component=src_cmpt,
            center=src_pt,
        )
    ]

    sim = mp.Simulation(
        resolution=RESOLUTION_UM,
        cell_size=cell_size,
        dimensions=1,
        boundary_layers=pml_layers,
        sources=sources,
    )

    tran_pt = mp.Vector3(0, 0, 0.5 * size_z_um - PML_UM)

    flux_mon = sim.add_flux(frequency, 0, 1, mp.FluxRegion(center=tran_pt))

    sim.run(
        until_after_sources=mp.stop_when_fields_decayed(25.0, src_cmpt, tran_pt, 1e-6)
    )

    flux = mp.get_fluxes(flux_mon)[0]

    return flux


def multilayer_stack(norm_flux: float) -> mpa.OptimizationProblem:
    """Sets up the adjoint optimization of a multilayer stack.

    Args:
      norm_flux: input flux to use for normalizing the objective function.

    Returns:
      A meep.adjoint.Optimization object for the simulation.
    """

    frequency = 1 / WAVELENGTH_UM
    pml_layers = [mp.PML(direction=mp.Z, thickness=PML_UM)]

    size_z_um = PML_UM + AIR_UM + DESIGN_REGION_SIZE.z + AIR_UM + PML_UM
    cell_size = mp.Vector3(0, 0, size_z_um)

    src_cmpt = mp.Ex
    src_pt = mp.Vector3(0, 0, -0.5 * size_z_um + PML_UM)
    sources = [
        mp.Source(
            mp.GaussianSource(frequency, fwidth=0.1 * frequency),
            component=src_cmpt,
            center=src_pt,
        )
    ]

    mat_1 = mp.Medium(index=N_LAYER_1)
    mat_2 = mp.Medium(index=N_LAYER_2)

    matgrid = mp.MaterialGrid(
        mp.Vector3(0, 0, NZ_SIM_GRID),
        mat_1,
        mat_2,
        weights=np.ones(NZ_SIM_GRID),
        do_averaging=False,
    )

    matgrid_region = mpa.DesignRegion(
        matgrid,
        volume=mp.Volume(center=mp.Vector3(), size=DESIGN_REGION_SIZE),
    )

    geometry = [
        mp.Block(
            material=matgrid, size=matgrid_region.size, center=matgrid_region.center
        )
    ]

    sim = mp.Simulation(
        resolution=RESOLUTION_UM,
        cell_size=cell_size,
        dimensions=1,
        boundary_layers=pml_layers,
        sources=sources,
        geometry=geometry,
    )

    tran_pt = mp.Vector3(0, 0, 0.5 * size_z_um - PML_UM)

    obj_args = [
        mpa.FourierFields(sim, mp.Volume(center=tran_pt), mp.Ex),
        mpa.FourierFields(sim, mp.Volume(center=tran_pt), mp.Hy),
    ]

    def obj_func(dft_ex, dft_hy):
        """Objective function for the optimization.

        Args:
          dft_ex, dft_hy: the discrete Fourier-transformed Ex and Hy fields.

        Returns:
          The transmittance through the stack.
        """

        return npa.real(npa.conj(dft_ex) * dft_hy) / norm_flux

    opt = mpa.OptimizationProblem(
        simulation=sim,
        objective_functions=obj_func,
        objective_arguments=obj_args,
        design_regions=[matgrid_region],
        frequencies=[frequency],
    )

    return opt


def nlopt_obj_func(layer_thickness_um: np.ndarray, grad: np.ndarray) -> float:
    """Objective function for NLopt.

    Args:
      layer_thickness_um: thickness of the layers in the stack.
      grad: the gradient with respect to the layer thicknesses, modified in
        place.

    Returns:
      The value of the objective function evaluated at the given layer thicknesses.
    """

    design_weights = levelset_and_smoothing(layer_thickness_um)

    obj_val, gradient = opt([design_weights])

    defvjp(levelset_and_smoothing, levelset_and_smoothing_vjp)
    gradient_backpropagate = tensor_jacobian_product(levelset_and_smoothing, 0)(
        layer_thickness_um, gradient
    )

    # TODO (oskooi): determine why factor of 0.5 is necessary.
    gradient_backpropagate = 0.5 * gradient_backpropagate

    if grad.size > 0:
        grad[:] = np.squeeze(gradient_backpropagate)

    print(f"iteration:, {obj_val[0]}, {layer_thickness_um}")

    return obj_val[0]


if __name__ == "__main__":
    algorithm = nlopt.LD_LBFGS

    # Lower and upper bounds for layer thicknesses.
    lower_bound = MIN_LAYER_UM * np.ones(NUM_LAYERS)
    upper_bound = MAX_LAYER_UM * np.ones(NUM_LAYERS)

    solver = nlopt.opt(algorithm, NUM_LAYERS)
    solver.set_lower_bounds(lower_bound)
    solver.set_upper_bounds(upper_bound)
    solver.set_min_objective(nlopt_obj_func)
    solver.set_ftol_abs(0.001)
    solver.set_xtol_abs(1 / RESOLUTION_UM)
    solver.set_maxeval(20)

    norm_flux = input_flux()
    opt = multilayer_stack(norm_flux)

    layer_thickness_um = 0.2 * np.ones(NUM_LAYERS)
    optimal_layer_thickness_um = solver.optimize(layer_thickness_um)
    optimal_obj_val = solver.last_optimum_value()
    result = solver.last_optimize_result()

    print(f"optimal_obj_val:, {optimal_obj_val}")
    print(f"optimal_layer_thickness_um:, {optimal_layer_thickness_um}")
    print(f"result:, {result}")
