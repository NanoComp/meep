{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimax Optimization using the Epigraph Formulation\n",
    "\n",
    "Our previous tutorials have demonstrated a mean squared error approach to minimization. In some applications, it's beneficial to perform a minimax optimization, where we minimize the worst performing error over a set of objective functions.\n",
    "\n",
    "Because meep's adjoint solver can calculate the gradient at multiple frequencies points using the same forward and adjoint solves, it's relatively easy to perform a minimax optimization for our bent waveguide example.\n",
    "\n",
    "Most minimax problems are difficult to solve because the gradient breaks down with min/max functions. We can overcome this by using the popular epigraph formulation, which introduces a dummy parameter and transforms the various additional objective functions as constraints.\n",
    "\n",
    "In this case, we'll generate a vector-valued objective function -- each element of said vector corresponds to the performance at each frequency point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import meep as mp\n",
    "import meep.adjoint as mpa\n",
    "import numpy as np\n",
    "from autograd import numpy as npa\n",
    "from autograd import tensor_jacobian_product, grad\n",
    "import nlopt\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.patches import Circle\n",
    "from scipy import special, signal\n",
    "\n",
    "mp.verbosity(0)\n",
    "Si = mp.Medium(index=3.4)\n",
    "SiO2 = mp.Medium(index=1.44)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the same setup as our original bent waveguide example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveguide_width = 0.5\n",
    "design_region_width = 2.5\n",
    "design_region_height = 2.5\n",
    "\n",
    "waveguide_length = 0.5\n",
    "\n",
    "pml_size = 1.0\n",
    "\n",
    "resolution = 20\n",
    "\n",
    "nf = 10\n",
    "frequencies = 1 / np.linspace(1.5, 1.6, nf)\n",
    "\n",
    "minimum_length = 0.09  # minimum length scale (microns)\n",
    "eta_i = (\n",
    "    0.5  # blueprint (or intermediate) design field thresholding point (between 0 and 1)\n",
    ")\n",
    "eta_e = 0.55  # erosion design field thresholding point (between 0 and 1)\n",
    "eta_d = 1 - eta_e  # dilation design field thresholding point (between 0 and 1)\n",
    "filter_radius = mpa.get_conic_radius_from_eta_e(minimum_length, eta_e)\n",
    "print(filter_radius)\n",
    "design_region_resolution = int(1 * resolution)\n",
    "\n",
    "Sx = 2 * pml_size + 2 * waveguide_length + design_region_width\n",
    "Sy = 2 * pml_size + design_region_height + 0.5\n",
    "cell_size = mp.Vector3(Sx, Sy)\n",
    "\n",
    "pml_layers = [mp.PML(pml_size)]\n",
    "\n",
    "fcen = 1 / 1.55\n",
    "width = 0.2\n",
    "fwidth = width * fcen\n",
    "source_center = [-Sx / 2 + pml_size + waveguide_length / 3, 0, 0]\n",
    "source_size = mp.Vector3(0, Sy, 0)\n",
    "kpoint = mp.Vector3(1, 0, 0)\n",
    "src = mp.GaussianSource(frequency=fcen, fwidth=fwidth)\n",
    "source = [\n",
    "    mp.EigenModeSource(\n",
    "        src,\n",
    "        eig_band=1,\n",
    "        direction=mp.NO_DIRECTION,\n",
    "        eig_kpoint=kpoint,\n",
    "        size=source_size,\n",
    "        center=source_center,\n",
    "    )\n",
    "]\n",
    "\n",
    "Nx = int(design_region_resolution * design_region_width)\n",
    "Ny = int(design_region_resolution * design_region_height)\n",
    "\n",
    "design_variables = mp.MaterialGrid(mp.Vector3(Nx, Ny), SiO2, Si, grid_type=\"U_MEAN\")\n",
    "design_region = mpa.DesignRegion(\n",
    "    design_variables,\n",
    "    volume=mp.Volume(\n",
    "        center=mp.Vector3(),\n",
    "        size=mp.Vector3(design_region_width, design_region_height, 0),\n",
    "    ),\n",
    ")\n",
    "\n",
    "x_g = np.linspace(-design_region_width / 2, design_region_width / 2, Nx)\n",
    "y_g = np.linspace(-design_region_height / 2, design_region_height / 2, Ny)\n",
    "X_g, Y_g = np.meshgrid(x_g, y_g, sparse=True, indexing=\"ij\")\n",
    "\n",
    "left_wg_mask = (X_g == -design_region_width / 2) & (np.abs(Y_g) <= waveguide_width / 2)\n",
    "top_wg_mask = (Y_g == design_region_width / 2) & (np.abs(X_g) <= waveguide_width / 2)\n",
    "Si_mask = left_wg_mask | top_wg_mask\n",
    "\n",
    "border_mask = (\n",
    "    (X_g == -design_region_width / 2)\n",
    "    | (X_g == design_region_width / 2)\n",
    "    | (Y_g == -design_region_height / 2)\n",
    "    | (Y_g == design_region_height / 2)\n",
    ")\n",
    "SiO2_mask = border_mask.copy()\n",
    "SiO2_mask[Si_mask] = False\n",
    "\n",
    "\n",
    "def mapping(x, eta, beta):\n",
    "    x = npa.where(Si_mask.flatten(), 1, npa.where(SiO2_mask.flatten(), 0, x))\n",
    "\n",
    "    # filter\n",
    "    filtered_field = mpa.conic_filter(\n",
    "        x,\n",
    "        filter_radius,\n",
    "        design_region_width,\n",
    "        design_region_height,\n",
    "        design_region_resolution,\n",
    "    )\n",
    "\n",
    "    # projection\n",
    "    projected_field = mpa.tanh_projection(filtered_field, beta, eta)\n",
    "\n",
    "    projected_field = (\n",
    "        npa.rot90(projected_field.T, 2) + projected_field\n",
    "    ) / 2  # 90-degree symmetry\n",
    "\n",
    "    # interpolate to actual materials\n",
    "    return projected_field.flatten()\n",
    "\n",
    "\n",
    "geometry = [\n",
    "    mp.Block(\n",
    "        center=mp.Vector3(x=-Sx / 4), material=Si, size=mp.Vector3(Sx / 2, 0.5, 0)\n",
    "    ),  # horizontal waveguide\n",
    "    mp.Block(\n",
    "        center=mp.Vector3(y=Sy / 4), material=Si, size=mp.Vector3(0.5, Sy / 2, 0)\n",
    "    ),  # vertical waveguide\n",
    "    mp.Block(\n",
    "        center=design_region.center, size=design_region.size, material=design_variables\n",
    "    ),  # design region\n",
    "    # mp.Block(center=design_region.center, size=design_region.size, material=design_variables,\n",
    "    #         e1=mp.Vector3(x=-1).rotate(mp.Vector3(z=1), np.pi/2), e2=mp.Vector3(y=1).rotate(mp.Vector3(z=1), np.pi/2))\n",
    "    #\n",
    "    # The commented lines above impose symmetry by overlapping design region with the same design variable. However,\n",
    "    # currently there is an issue of doing that; instead, we use an alternative approach to impose symmetry.\n",
    "    # See https://github.com/NanoComp/meep/issues/1984 and https://github.com/NanoComp/meep/issues/2093\n",
    "]\n",
    "\n",
    "sim = mp.Simulation(\n",
    "    cell_size=cell_size,\n",
    "    boundary_layers=pml_layers,\n",
    "    geometry=geometry,\n",
    "    sources=source,\n",
    "    default_material=SiO2,\n",
    "    resolution=resolution,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll slightly modify our objective function. We'll remove the `mean` function which was previously required to ensure our objective function is scalar valued. Instead, our objective function will be vector valued. We'll also return the *error* of our bend (`1-power`) rather than the raw power itself. This way we can formulate a minimax problem rather than a maximin problem -- although we could setup our optimization problem that way too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 1\n",
    "\n",
    "TE0 = mpa.EigenmodeCoefficient(\n",
    "    sim,\n",
    "    mp.Volume(\n",
    "        center=mp.Vector3(x=-Sx / 2 + pml_size + 2 * waveguide_length / 3),\n",
    "        size=mp.Vector3(y=Sy),\n",
    "    ),\n",
    "    mode,\n",
    ")\n",
    "TE_top = mpa.EigenmodeCoefficient(\n",
    "    sim,\n",
    "    mp.Volume(\n",
    "        center=mp.Vector3(0, Sx / 2 - pml_size - 2 * waveguide_length / 3, 0),\n",
    "        size=mp.Vector3(x=Sx),\n",
    "    ),\n",
    "    mode,\n",
    ")\n",
    "ob_list = [TE0, TE_top]\n",
    "\n",
    "\n",
    "def J(source, top):\n",
    "    power = npa.abs(top / source) ** 2\n",
    "    return 1 - power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = mpa.OptimizationProblem(\n",
    "    simulation=sim,\n",
    "    objective_functions=J,\n",
    "    objective_arguments=ob_list,\n",
    "    design_regions=[design_region],\n",
    "    frequencies=frequencies,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our objective function that we pass to nlopt is rather simple. We'll introduce a dummy parameter `t`. The goal of the optimization problem will be to simply minimize the value of `t`. The gradient of this functional is rather straightforward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_history = []\n",
    "cur_iter = [0]\n",
    "\n",
    "\n",
    "def f(x, grad):\n",
    "    t = x[0]  # \"dummy\" parameter\n",
    "    v = x[1:]  # design parameters\n",
    "    if grad.size > 0:\n",
    "        grad[0] = 1\n",
    "        grad[1:] = 0\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key to the epigraph formulation (and most nonlinear optimization problems) lies in the constraints. We'll define one constraint for every frequency point of interest ($f_i$). We'll define our constraint as \n",
    "\n",
    "$$f_i < t$$\n",
    "\n",
    "where $t$ is the previosuly defined dummy parameter. Each constraint function is then defined by\n",
    "\n",
    "$$ c_i = f_i-t $$\n",
    "\n",
    "within some tolerance.\n",
    "\n",
    "More detail about this formulation can be found in the nlopt [documentation](https://nlopt.readthedocs.io/en/latest/NLopt_Introduction/#equivalent-formulations-of-optimization-problems)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c(result, x, gradient, eta, beta):\n",
    "    print(\n",
    "        \"Current iteration: {}; current eta: {}, current beta: {}\".format(\n",
    "            cur_iter[0], eta, beta\n",
    "        )\n",
    "    )\n",
    "\n",
    "    t = x[0]  # dummy parameter\n",
    "    v = x[1:]  # design parameters\n",
    "\n",
    "    f0, dJ_du = opt([mapping(v, eta, beta)])\n",
    "\n",
    "    # Backprop the gradients through our mapping function\n",
    "    my_grad = np.zeros(dJ_du.shape)\n",
    "    for k in range(opt.nf):\n",
    "        my_grad[:, k] = tensor_jacobian_product(mapping, 0)(v, eta, beta, dJ_du[:, k])\n",
    "\n",
    "    # Assign gradients\n",
    "    if gradient.size > 0:\n",
    "        gradient[:, 0] = -1  # gradient w.r.t. \"t\"\n",
    "        gradient[:, 1:] = my_grad.T  # gradient w.r.t. each frequency objective\n",
    "\n",
    "    result[:] = np.real(f0) - t\n",
    "\n",
    "    # store results\n",
    "    evaluation_history.append(np.real(f0))\n",
    "\n",
    "    # visualize\n",
    "    plt.figure()\n",
    "    ax = plt.gca()\n",
    "    opt.plot2D(\n",
    "        False,\n",
    "        ax=ax,\n",
    "        plot_sources_flag=False,\n",
    "        plot_monitors_flag=False,\n",
    "        plot_boundaries_flag=False,\n",
    "    )\n",
    "    circ = Circle((2, 2), minimum_length / 2)\n",
    "    ax.add_patch(circ)\n",
    "    ax.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    cur_iter[0] = cur_iter[0] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now run our optimizer in loop. The loop will increase beta and reset the optimizer, which is important since the cost function changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = nlopt.LD_MMA\n",
    "n = Nx * Ny  # number of parameters\n",
    "\n",
    "# Initial guess\n",
    "x = np.ones((n,)) * 0.5\n",
    "x[Si_mask.flatten()] = 1  # set the edges of waveguides to silicon\n",
    "x[SiO2_mask.flatten()] = 0  # set the other edges to SiO2\n",
    "\n",
    "# lower and upper bounds\n",
    "lb = np.zeros((Nx * Ny,))\n",
    "lb[Si_mask.flatten()] = 1\n",
    "ub = np.ones((Nx * Ny,))\n",
    "ub[SiO2_mask.flatten()] = 0\n",
    "\n",
    "# insert dummy parameter bounds and variable\n",
    "x = np.insert(x, 0, 0.5)  # our initial guess for the worst error\n",
    "lb = np.insert(lb, 0, 0)  # we can't get less than 0 error!\n",
    "ub = np.insert(ub, 0, 1)  # we can't get more than 1 error!\n",
    "\n",
    "cur_beta = 4\n",
    "beta_scale = 2\n",
    "num_betas = 6\n",
    "update_factor = 12\n",
    "for iters in range(num_betas):\n",
    "    solver = nlopt.opt(algorithm, n + 1)\n",
    "    solver.set_lower_bounds(lb)\n",
    "    solver.set_upper_bounds(ub)\n",
    "    solver.set_min_objective(f)\n",
    "    solver.set_maxeval(update_factor)\n",
    "    solver.add_inequality_mconstraint(\n",
    "        lambda r, x, g: c(r, x, g, eta_i, cur_beta), np.array([1e-6] * nf)\n",
    "    )\n",
    "    x[:] = solver.optimize(x)\n",
    "    cur_beta = cur_beta * beta_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are optimizing over the entire frequency band, we can visualize the upper and lower bounds of the device's performance as a function of iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = 1 - np.min(evaluation_history, axis=1)\n",
    "ub = 1 - np.max(evaluation_history, axis=1)\n",
    "mean = 1 - np.mean(evaluation_history, axis=1)\n",
    "\n",
    "num_iters = lb.size\n",
    "\n",
    "plt.figure()\n",
    "plt.fill_between(\n",
    "    np.arange(1, num_iters + 1), 10 * np.log10(lb), 10 * np.log10(ub), alpha=0.3\n",
    ")\n",
    "plt.plot(10 * np.log10(mean), \"o-\")\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Average Insertion Loss (dB)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot our results and see the resulting geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.update_design([mapping(x[1:], eta_i, cur_beta)])\n",
    "plt.figure()\n",
    "ax = plt.gca()\n",
    "opt.plot2D(\n",
    "    False,\n",
    "    ax=ax,\n",
    "    plot_sources_flag=False,\n",
    "    plot_monitors_flag=False,\n",
    "    plot_boundaries_flag=False,\n",
    ")\n",
    "circ = Circle((2, 2), minimum_length / 2)\n",
    "ax.add_patch(circ)\n",
    "ax.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we'll check the final frequency response. We see that the response is much \"flatter\" across the band, and the worst performing frequency is much better than with the MSE approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0, dJ_du = opt([mapping(x[1:], eta_i, cur_beta // 2)], need_gradient=False)\n",
    "frequencies = opt.frequencies\n",
    "source_coef, top_coef = opt.get_objective_arguments()\n",
    "\n",
    "top_profile = np.abs(top_coef / source_coef) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(1 / frequencies, top_profile * 100, \"-o\")\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Wavelength (microns)\")\n",
    "plt.ylabel(\"Transmission (%)\")\n",
    "# plt.ylim(70,100)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(1 / frequencies, 10 * np.log10(top_profile), \"-o\")\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Wavelength (microns)\")\n",
    "plt.ylabel(\"Insertion Loss (dB)\")\n",
    "# plt.ylim(-0.1,0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, it is very easy to implement design constraints and density parameter operations using the native adjoint solver interface. One could use this same design flow to implement robus optimization over many frequency points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
