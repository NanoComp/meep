{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering and Thresholding Design Parameters and Broadband Objective Functions\n",
    "\n",
    "While cheap gradients are always appreciated, we noticed that the optimizer and adjoint solver often produce devices that are impossible to fabricate. They tend to continuously vary the refractive index and produce small feature sizes. Furthermore, the lack of constraint often throws the optimizer into local minima, stunting the overall progress of the solver.\n",
    "\n",
    "To overcome this, the Topology Optimization (TO) community often implements linear and nonlinear functional transforms on the design parameters before projecting them onto the simulation domain. For example, we can blur many of the small design parameters together using a conic filter, and subsequently threshold using sigmoid like functions.\n",
    "\n",
    "The resulting parameters can include constraints, like minimum lengths scales, and project the cost function into a more friendly (and sometimes less friendly) design space.\n",
    "\n",
    "We'll examine how to accomplish these goals using native `autograd` functions and meep's adjoint solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import meep as mp\n",
    "import meep.adjoint as mpa\n",
    "import numpy as np\n",
    "from autograd import numpy as npa\n",
    "from autograd import tensor_jacobian_product, grad\n",
    "import nlopt\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.patches import Circle\n",
    "from scipy import special, signal\n",
    "\n",
    "mp.verbosity(0)\n",
    "Si = mp.Medium(index=3.4)\n",
    "SiO2 = mp.Medium(index=1.44)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's choose our basic geometry parameters, along with the frequency range to simulate. If our frequency points are too close together than the resulting adjoint simulation may take longer to simulate each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveguide_width = 0.5\n",
    "design_region_width = 2.5\n",
    "design_region_height = 2.5\n",
    "\n",
    "waveguide_length = 0.5\n",
    "\n",
    "pml_size = 1.0\n",
    "\n",
    "resolution = 30\n",
    "\n",
    "frequencies = 1 / np.linspace(1.5, 1.6, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll specify our smoothing filter radius (in microns). This is determined by our minimum length scale and erosion threshold point. In this example, we won't actually enforce the length scale constraints, but the following machinery is required to do so.\n",
    "\n",
    "We also need to specify the number of design parameters per meep pixel we want to set up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum_length = 0.09  # minimum length scale (microns)\n",
    "eta_i = (\n",
    "    0.5  # blueprint (or intermediate) design field thresholding point (between 0 and 1)\n",
    ")\n",
    "eta_e = 0.55  # erosion design field thresholding point (between 0 and 1)\n",
    "eta_d = 1 - eta_e  # dilation design field thresholding point (between 0 and 1)\n",
    "filter_radius = mpa.get_conic_radius_from_eta_e(minimum_length, eta_e)\n",
    "print(filter_radius)\n",
    "design_region_resolution = int(1 * resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we'll generate our simulation cell with the specified sources, boundary layers, geometry, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sx = 2 * pml_size + 2 * waveguide_length + design_region_width\n",
    "Sy = 2 * pml_size + design_region_height + 0.5\n",
    "cell_size = mp.Vector3(Sx, Sy)\n",
    "\n",
    "pml_layers = [mp.PML(pml_size)]\n",
    "\n",
    "fcen = 1 / 1.55\n",
    "width = 0.2\n",
    "fwidth = width * fcen\n",
    "source_center = [-Sx / 2 + pml_size + waveguide_length / 3, 0, 0]\n",
    "source_size = mp.Vector3(0, Sy, 0)\n",
    "kpoint = mp.Vector3(1, 0, 0)\n",
    "src = mp.GaussianSource(frequency=fcen, fwidth=fwidth)\n",
    "source = [\n",
    "    mp.EigenModeSource(\n",
    "        src,\n",
    "        eig_band=1,\n",
    "        direction=mp.NO_DIRECTION,\n",
    "        eig_kpoint=kpoint,\n",
    "        size=source_size,\n",
    "        center=source_center,\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set up our design region. The defauly grid type behaves just like any other geometry object -- the last object in the tree overides any objects underneath it. In some cases, it's important to *average* overlapping design regions, i.e. to enforce particular symmetries. To enable this capability, we'll set our design variables to use the `U_MEAN` grid type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nx = int(design_region_resolution * design_region_width)\n",
    "Ny = int(design_region_resolution * design_region_height)\n",
    "\n",
    "design_variables = mp.MaterialGrid(mp.Vector3(Nx, Ny), SiO2, Si, grid_type=\"U_MEAN\")\n",
    "design_region = mpa.DesignRegion(\n",
    "    design_variables,\n",
    "    volume=mp.Volume(\n",
    "        center=mp.Vector3(),\n",
    "        size=mp.Vector3(design_region_width, design_region_height, 0),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimizer doesn't know anything about the geometry outside of the design region. We can \"hint\" what parts of the design must be waveguides by forcing boundry constraints. We'll build bitmasks that map the border of the design regions to either silicon or silicon dioxide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_g = np.linspace(-design_region_width / 2, design_region_width / 2, Nx)\n",
    "y_g = np.linspace(-design_region_height / 2, design_region_height / 2, Ny)\n",
    "X_g, Y_g = np.meshgrid(x_g, y_g, sparse=True, indexing=\"ij\")\n",
    "\n",
    "left_wg_mask = (X_g == -design_region_width / 2) & (np.abs(Y_g) <= waveguide_width / 2)\n",
    "top_wg_mask = (Y_g == design_region_width / 2) & (np.abs(X_g) <= waveguide_width / 2)\n",
    "Si_mask = left_wg_mask | top_wg_mask\n",
    "\n",
    "border_mask = (\n",
    "    (X_g == -design_region_width / 2)\n",
    "    | (X_g == design_region_width / 2)\n",
    "    | (Y_g == -design_region_height / 2)\n",
    "    | (Y_g == design_region_height / 2)\n",
    ")\n",
    "SiO2_mask = border_mask.copy()\n",
    "SiO2_mask[Si_mask] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll define various filters that perform smoothing, projection, and material scaling. We'll be sure to use autograd so that we can easily backpropogate our gradient provided by the adjoint solver. We have some smoothing and thresholding filters already defined in the adjoint package that we'll use here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping(x, eta, beta):\n",
    "    x = npa.where(Si_mask.flatten(), 1, npa.where(SiO2_mask.flatten(), 0, x))\n",
    "    # filter\n",
    "    filtered_field = mpa.conic_filter(\n",
    "        x,\n",
    "        filter_radius,\n",
    "        design_region_width,\n",
    "        design_region_height,\n",
    "        design_region_resolution,\n",
    "    )\n",
    "\n",
    "    # projection\n",
    "    projected_field = mpa.tanh_projection(filtered_field, beta, eta)\n",
    "\n",
    "    # interpolate to actual materials\n",
    "    return projected_field.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build the geometry and simulation objects. We can force a rotational symmetry by adding extra blocks with the same design variables, but different basis vectors (`e1`, `e2`, etc.) In our case, we need one additional block object rotated by 90 degrees.\n",
    "\n",
    "Because our design variables are using the `U_MEAN` scheme, the adjoint solver will search for all of the material grids at each point in our design region and average the overlapping design variables. This way, we can enforce our symmetry constraint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geometry = [\n",
    "    mp.Block(\n",
    "        center=mp.Vector3(x=-Sx / 4), material=Si, size=mp.Vector3(Sx / 2, 0.5, 0)\n",
    "    ),  # horizontal waveguide\n",
    "    mp.Block(\n",
    "        center=mp.Vector3(y=Sy / 4), material=Si, size=mp.Vector3(0.5, Sy / 2, 0)\n",
    "    ),  # vertical waveguide\n",
    "    mp.Block(\n",
    "        center=design_region.center, size=design_region.size, material=design_variables\n",
    "    ),  # design region\n",
    "    mp.Block(\n",
    "        center=design_region.center,\n",
    "        size=design_region.size,\n",
    "        material=design_variables,\n",
    "        e1=mp.Vector3(x=-1).rotate(mp.Vector3(z=1), np.pi / 2),\n",
    "        e2=mp.Vector3(y=1).rotate(mp.Vector3(z=1), np.pi / 2),\n",
    "    ),\n",
    "]\n",
    "\n",
    "sim = mp.Simulation(\n",
    "    cell_size=cell_size,\n",
    "    boundary_layers=pml_layers,\n",
    "    geometry=geometry,\n",
    "    sources=source,\n",
    "    default_material=SiO2,\n",
    "    resolution=resolution,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's formulate our broadband objective function. To keep it simple we'll just minimize the sum of the error, where the error is the L2 norm between the transmission and 1 (i.e. the desired profile)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 1\n",
    "\n",
    "TE0 = mpa.EigenmodeCoefficient(\n",
    "    sim,\n",
    "    mp.Volume(\n",
    "        center=mp.Vector3(x=-Sx / 2 + pml_size + 2 * waveguide_length / 3),\n",
    "        size=mp.Vector3(y=Sy),\n",
    "    ),\n",
    "    mode,\n",
    ")\n",
    "TE_top = mpa.EigenmodeCoefficient(\n",
    "    sim,\n",
    "    mp.Volume(\n",
    "        center=mp.Vector3(0, Sx / 2 - pml_size - 2 * waveguide_length / 3, 0),\n",
    "        size=mp.Vector3(x=Sx),\n",
    "    ),\n",
    "    mode,\n",
    ")\n",
    "ob_list = [TE0, TE_top]\n",
    "\n",
    "\n",
    "def J(source, top):\n",
    "    power = npa.abs(top / source)\n",
    "    return npa.mean(power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = mpa.OptimizationProblem(\n",
    "    simulation=sim,\n",
    "    objective_functions=J,\n",
    "    objective_arguments=ob_list,\n",
    "    design_regions=[design_region],\n",
    "    frequencies=frequencies,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's see how well our filtering and projection functions work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho_vector = np.random.rand(Nx * Ny)\n",
    "opt.update_design([mapping(rho_vector, eta_i, 1e3)])\n",
    "opt.plot2D(True, output_plane=mp.Volume(center=(0, 0, 0), size=(3, 3, 0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can increase our `beta` term, which controls the thresholding, and simultaneously sweep our perturbation term (`delta`) which is used to generate erosion and dilation geometries typically used in the literature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 2048\n",
    "\n",
    "plt.figure()\n",
    "ax1 = plt.subplot(1, 3, 1)\n",
    "opt.update_design([mapping(rho_vector, 0.498, beta)])\n",
    "opt.plot2D(True, ax=ax1, output_plane=mp.Volume(center=(0, 0, 0), size=(3, 3, 0)))\n",
    "plt.title(\"Dilation\")\n",
    "\n",
    "ax2 = plt.subplot(1, 3, 2)\n",
    "opt.update_design([mapping(rho_vector, 0.5, beta)])\n",
    "opt.plot2D(True, ax=ax2, output_plane=mp.Volume(center=(0, 0, 0), size=(3, 3, 0)))\n",
    "plt.title(\"Intermediate\")\n",
    "\n",
    "ax3 = plt.subplot(1, 3, 3)\n",
    "opt.update_design([mapping(rho_vector, 0.502, beta)])\n",
    "opt.plot2D(True, ax=ax3, output_plane=mp.Volume(center=(0, 0, 0), size=(3, 3, 0)))\n",
    "plt.title(\"Erosion\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our framwork in place, we can define our `nlopt` cost function wrapper that also includes our mapping layers and their corresponding gradients. We'll systematically increase our `beta` term so that the thresholding gradually turns on, as suggested by the literature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_history = []\n",
    "cur_iter = [0]\n",
    "\n",
    "\n",
    "def f(v, gradient, cur_beta):\n",
    "    print(\"Current iteration: {}\".format(cur_iter[0] + 1))\n",
    "\n",
    "    f0, dJ_du = opt([mapping(v, eta_i, cur_beta)])  # compute objective and gradient\n",
    "\n",
    "    if gradient.size > 0:\n",
    "        gradient[:] = tensor_jacobian_product(mapping, 0)(\n",
    "            v, eta_i, cur_beta, np.sum(dJ_du, axis=1)\n",
    "        )  # backprop\n",
    "\n",
    "    evaluation_history.append(np.real(f0))\n",
    "\n",
    "    plt.figure()\n",
    "    ax = plt.gca()\n",
    "    opt.plot2D(\n",
    "        False,\n",
    "        ax=ax,\n",
    "        plot_sources_flag=False,\n",
    "        plot_monitors_flag=False,\n",
    "        plot_boundaries_flag=False,\n",
    "    )\n",
    "    circ = Circle((2, 2), minimum_length / 2)\n",
    "    ax.add_patch(circ)\n",
    "    ax.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    cur_iter[0] = cur_iter[0] + 1\n",
    "\n",
    "    return np.real(f0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now run our optimizer in loop. The loop will increase beta and reset the optimizer, which is important since the cost function changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = nlopt.LD_MMA\n",
    "n = Nx * Ny  # number of parameters\n",
    "\n",
    "# Initial guess\n",
    "x = np.ones((n,)) * 0.5\n",
    "x[Si_mask.flatten()] = 1  # set the edges of waveguides to silicon\n",
    "x[SiO2_mask.flatten()] = 0  # set the other edges to SiO2\n",
    "\n",
    "# lower and upper bounds\n",
    "lb = np.zeros((Nx * Ny,))\n",
    "lb[Si_mask.flatten()] = 1\n",
    "ub = np.ones((Nx * Ny,))\n",
    "ub[SiO2_mask.flatten()] = 0\n",
    "\n",
    "cur_beta = 4\n",
    "beta_scale = 2\n",
    "num_betas = 6\n",
    "update_factor = 12\n",
    "for iters in range(num_betas):\n",
    "    solver = nlopt.opt(algorithm, n)\n",
    "    solver.set_lower_bounds(lb)\n",
    "    solver.set_upper_bounds(ub)\n",
    "    solver.set_max_objective(lambda a, g: f(a, g, cur_beta))\n",
    "    solver.set_maxeval(update_factor)\n",
    "    x[:] = solver.optimize(x)\n",
    "    cur_beta = cur_beta * beta_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll wait for a few minutes (or longer) and visualize the results. We see that every time `beta` increases it either drives the cost function out of a local minimum or into a poorer spot. It gets harder to converge as `beta` increases. This is expected as the gradient starts to swing wildy at these thresholded transition regions. Regardless, we are still able to generate a somewhat smoothed structure after just 72 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(10 * np.log10(evaluation_history), \"o-\")\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Average Insertion Loss (dB)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be sure, we can plot our results and see the resulting geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.update_design([mapping(x, eta_i, cur_beta)])\n",
    "plt.figure()\n",
    "ax = plt.gca()\n",
    "opt.plot2D(\n",
    "    False,\n",
    "    ax=ax,\n",
    "    plot_sources_flag=False,\n",
    "    plot_monitors_flag=False,\n",
    "    plot_boundaries_flag=False,\n",
    ")\n",
    "circ = Circle((2, 2), minimum_length / 2)\n",
    "ax.add_patch(circ)\n",
    "ax.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course we want to check the final frequency response. We can run another forward run to pull the objective function parameters and calculate the transmisson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0, dJ_du = opt([mapping(x, eta_i, cur_beta)], need_gradient=False)\n",
    "frequencies = opt.frequencies\n",
    "source_coef, top_coef = opt.get_objective_arguments()\n",
    "\n",
    "top_profile = np.abs(top_coef / source_coef) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(1 / frequencies, top_profile * 100, \"-o\")\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Wavelength (microns)\")\n",
    "plt.ylabel(\"Transmission (%)\")\n",
    "plt.ylim(98, 100)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(1 / frequencies, 10 * np.log10(top_profile), \"-o\")\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Wavelength (microns)\")\n",
    "plt.ylabel(\"Insertion Loss (dB)\")\n",
    "plt.ylim(-0.1, 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, it is very easy to implement design constraints and density parameter operations using the native adjoint solver interface. One could use this same design flow to implement robus optimization over many frequency points."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
